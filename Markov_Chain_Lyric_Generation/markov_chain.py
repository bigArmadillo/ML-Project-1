# -*- coding: utf-8 -*-
"""Markov_Chain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o6R32Mw773Ca8mqqS7rB-uHytSrbdeo6

# Building supervised learning program
"""

#Creating the transition table
def generateTable(data,k=4):
    
    T = {}
    for i in range(len(data)-k):
        X = data[i:i+k]
        Y = data[i+k]
        #print("X  %s and Y %s  "%(X,Y))
        
        if T.get(X) is None:
            T[X] = {}
            T[X][Y] = 1
        else:
            if T[X].get(Y) is None:
                T[X][Y] = 1
            else:
                T[X][Y] += 1
    
    return T

T = generateTable("a quick brown fox jumps over the lazy dog. The jump was dope but false.")
print(T)

#Adding prob to each
def convertFreqIntoProb(T):     
    for kx in T.keys():
        s = float(sum(T[kx].values()))
        for k in T[kx].keys():
            T[kx][k] = T[kx][k]/s
                
    return T

T = convertFreqIntoProb(T)
print(T)

from google.colab import files
uploaded = files.upload()

text_path = "Apna Time Aayega.txt"
def load_text(filename):
    with open(filename,encoding='utf8') as f:
        return f.read().lower()
    
text = load_text(text_path)

text

"""# Training Markov Chain model"""

def trainMarkovChain(text,k=4):
    
    T = generateTable(text,k)
    T = convertFreqIntoProb(T)
    
    return T

preprocessed_data = trainMarkovChain(text)

print(preprocessed_data)

"""# Generating Texts

"""

import numpy as np
import random

#Predict the next letter
def sample_next(context,T,k):
    context = context[-k:]
    if T.get(context) is None:
        return " "
    possible_Chars = list(T[context].keys())
    possible_values = list(T[context].values())
    
    #print(possible_Chars)
    #print(possible_values)

    random.seed(11)
    return np.random.choice(possible_Chars,p=possible_values)

#Generating text
def model(starting_sent,k=4,maxLen=1000):
    
    sentence = starting_sent
    context = starting_sent[-k:]
    
    for ix in range(maxLen):
        next_prediction = sample_next(context,preprocessed_data,k)
        sentence += next_prediction
        context = sentence[-k:]
    return sentence



output_text = model("apna",k=4,maxLen=2000)
print(output_text)

f = open("submission3.txt","w+",encoding = "utf8")
f.write(output_text)
f.close()











