# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fZXUnhNuveYQ2dqNRhwaq3t5PVSAhPgY
"""

from keras.datasets import mnist

from keras.layers import *

from keras.layers.advanced_activations import LeakyReLU

from keras.models import Sequential, Model

from keras.optimizers import Adam

import numpy as np
import matplotlib.pyplot as plt
import math

(x_train,_),(_,_) = mnist.load_data()

print(x_train.shape)

type(x_train)

plt.imshow(x_train[1],cmap='gray')

##Normalize the data in [-1,1]
x_train = x_train.astype('float32')

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x = sc.fit_transform(x_train)

##3-D values can be transformed with STandardScaler
x = (x_train-127.5)/127.5
print(x.min(),x.max())

x.shape

total_epochs=50
batch_size=128
no_of_batches = int(x.shape[0]/batch_size)
half_batch =128
noise_dim = 100 ##upsample into 784
adam = Adam(lr=2e-4,beta_1=0.5)  ##special parameters for GAN

##Generator
##input noise 100 dim, outputs vector 784 dim - upsampling

generator = Sequential()
generator.add(Dense(256,input_shape=(noise_dim,)))
generator.add(LeakyReLU(0.2))
generator.add(Dense(512))
generator.add(LeakyReLU(0.2))
generator.add(Dense(1024))
generator.add(LeakyReLU(0.2))
generator.add(Dense(784,activation='tanh'))

generator.compile(loss='binary_crossentropy',optimizer=adam)
generator.summary()

##Discrimator
##784->1  - downsampling

discriminator = Sequential()
discriminator.add(Dense(512,input_shape=(784,)))
discriminator.add(LeakyReLU(0.2))
discriminator.add(Dense(256))
discriminator.add(LeakyReLU(0.2))
discriminator.add(Dense(1,activation='sigmoid'))

discriminator.compile(loss='binary_crossentropy',optimizer=adam)
discriminator.summary()

##GAN
#step 1 - freeze generator, train D
#step 2 - freeze discriminator, train G

##step 2

discriminator.trainable = False
gan_input = Input(shape=(noise_dim,))
generated_img = generator(gan_input)
gan_output = discriminator(generated_img)

##Functional API
model = Model(gan_input, gan_output)
model.compile(loss='binary_crossentropy',optimizer=adam)

type(generator)

model.summary()

x = x.reshape(-1,784)
x.shape

!mkdir images

def save_imgs(epoch,samples=100):
    
    noise = np.random.normal(0,1,size=(samples,noise_dim))
    generated_imgs = generator.predict(noise)
    generated_imgs = generated_imgs.reshape(samples,28,28)
    
    plt.figure(figsize=(10,10))
    for i in range(samples):
        plt.subplot(10,10,i+1)
        plt.imshow(generated_imgs[i],interpolation='nearest',cmap='gray')
        plt.axis("off")
        
    plt.tight_layout()
    plt.savefig('images/gan_output_epoch_{0}.png'.format(epoch+1))
    plt.show()

##Training Loop - not as simple as .fit()

for epoch in range(total_epochs):
  epoch_g_loss = 0
  epoch_d_loss = 0

  ##Mini Batch SGD
  for step in range(no_of_batches):

    ##Step-1 Discriminator
    #50% Real Data + 50% Fake Data

    ##Real Data
    idx = np.random.randint(0,x.shape[0],half_batch)
    real_imgs = x[idx]

    ##Fake Data
    noise = np.random.normal(0,1,size=(half_batch,noise_dim))
    fake_imgs = generator.predict(noise)  #Forward

    ##Labels
    real_y = np.ones((half_batch,1))*0.9  #one-sided label smoothing for D
    fake_y = np.zeros((half_batch,1))

    ##Train our Discriminator
    d_loss_real = discriminator.train_on_batch(real_imgs,real_y)
    d_loss_fake = discriminator.train_on_batch(fake_imgs,fake_y)
    d_loss = 0.5*d_loss_real + 0.5*d_loss_fake

    epoch_d_loss += d_loss


    ##Step-2 Training the Generator (considering D frozen)

    noise = np.random.normal(0,1,size=(batch_size,noise_dim))
    ground_truth_y = np.ones((batch_size,1))
    g_loss = model.train_on_batch(noise,ground_truth_y)
    epoch_g_loss += g_loss


  print("Epoch %d, D loss is %.4f, and G loss is %.4f" %((epoch+1),epoch_d_loss/no_of_batches,epoch_g_loss/no_of_batches))
  
  if (epoch+1)%5==0:
        save_imgs(epoch)

!ls

!zip -r /content/images.zip /content/images

from google.colab import files
files.download('images.zip')



